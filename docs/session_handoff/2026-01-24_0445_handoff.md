# Session Handoff: Google Maps Scraper - Missing Extra Reviews Debugging

Read this file to continue where the previous session left off. The "Extra Reviews" feature is extracting data (as seen in logs), but the results are not appearing in the UI or the database.

## Project Location
`D:\Websites\GMaps_scraper_gosom`

## Context Files to Read First
1. `docs/active_context.md` - current state overview
2. `source/gmaps/place.go` - review extraction orchestration
3. `source/gmaps/reviews.go` - RPC/DOM extraction logic
4. `source/gmaps/entry.go` - data structure and persistence

## The Core Problem
The user requests "extra reviews" (e.g., 21). The scraper logs show that it finds the reviews:
`[ExtraReviews] Got 2 RPC pages`
`RPC extraction successful: 2 review pages, ~40 reviews`

However:
1.  The UI only shows the default 8 reviews.
2.  SQL queries on the Supabase `results` table show `data->'user_reviews_extended'` is `null`.

## Suspected Root Causes
-   **Type Assertion Failure?**: I suspect `resp.Meta` data passing between `BrowserActions` and `Process` might be failing. I've already refactored it to use raw `[][]byte` for robustness, but it hasn't resolved the issue.
-   **JSON Marshaling**: The `Review` struct in `entry.go` lacks JSON tags. While it matches the TypeScript interface casing (Capitalized), it might be worth adding explicit `json:"..."` tags to both `Review` and `Entry` fields.
-   **Binaries/Docker**: Ensure the `docker build` truly updated the image being run by the Next.js app. The app uses `google-maps-scraper:custom`.
-   **Sync Logic**: The auto-sync logic in `api/jobs/route.ts` was recently fixed to use `upsert` instead of `insert`. This was to prevent repeat runs from being blocked by unique constraints.

## Recent Changes (Last Session)
-   Refactored `place.go` to pass review data via `resp.Meta["reviews_pages"]` as `[][]byte`.
-   Added helper methods `HasPages()`, `CountPages()`, and `GetPages()` to the `FetchReviewsResponse` struct in the Go scraper.
-   Initialized `UserReviewsExtended` as an empty slice `[]` in `EntryFromJSON` to avoid `null` in DB.
-   Rebuilt Docker image `google-maps-scraper:custom`.

## What's Left to Do
-   [ ] **Print the Entry**: Add a `fmt.Printf("%+v\n", entry)` or JSON dump inside `PlaceJob.Process` to see if `UserReviewsExtended` is actually populated right before returning.
-   [ ] **Inspect results.json**: Prevent the container from being removed (comment out `docker rm` in `lib/docker.ts`) and manually `cat` the `results.json` inside the container or the extracted file.
-   [ ] **Review Writer Logic**: Check if `scrapemate`'s JSON writer handles unexported fields or missing tags in a way that excludes `UserReviewsExtended`.
-   [ ] **Frontend Check**: Confirm the `user_reviews_extended` field isn't being filtered out or ignored in the sync API before insertion.

## Verification Steps
1. Run a job with `extraReviews: 21`.
2. Check container logs for `[ExtraReviews]` messages.
3. Query Supabase: `SELECT data->'user_reviews_extended' FROM results WHERE job_id = '...'`.
4. If `null`, the issue is in the Scraper -> JSON pipeline. If `[]` but empty, the issue is in the Extraction -> Struct pipeline.
