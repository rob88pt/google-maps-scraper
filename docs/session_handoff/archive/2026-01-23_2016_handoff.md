# Session Handoff: JSON Output + Post-Processing Implementation

Read this file to continue where the previous session left off.

## Project Location
`D:\Websites\GMaps_scraper_gosom\leads-command-center`

## Context Files to Read First
1. `docs/session_handoff/2026-01-23_1925_handoff.md` - Previous context
2. `src/lib/docker.ts` - Updated with JSON output and post-processing functions
3. `src/app/api/jobs/[id]/sync/route.ts` - NEW: API endpoint for syncing results
4. `source/FORK_CHANGELOG.md` - Documents our custom scraper modifications

## What Was Done This Session

### Root Cause Identified
The upstream scraper's `-dsn` mode requires a `gmaps_jobs` table for its job queue system. Our Supabase doesn't have this table, causing the error:
```
ERROR: relation "gmaps_jobs" does not exist (SQLSTATE 42P01)
```

### Decision Made
Use **JSON output + post-processing** approach instead of DSN mode:
- Scraper writes to local `results.json` file (no database dependency)
- Our app post-processes the file and inserts into Supabase with `job_id` and `user_id`
- Decoupled from upstream schema changes

### Code Changes Made

1. **`src/lib/docker.ts`** - Updated:
   - Removed `-dsn` flag from Docker args
   - Changed to ALWAYS use JSON output (not CSV) for full data
   - Added imports: `readFile`, `existsSync`
   - Added `getJobResultsPath(jobId)` helper
   - Added `getJobDir(jobId)` helper
   - Added `ScrapedLead` interface for typed lead data
   - Added `processJobResults(jobId)` - parses NDJSON and returns structured leads
   - Added `cleanupJobFiles(jobId)` - removes temp files after processing

2. **`src/app/api/jobs/[id]/sync/route.ts`** - NEW:
   - `POST /api/jobs/[id]/sync` - Processes results file, inserts into Supabase
   - `GET /api/jobs/[id]/sync` - Checks if container exited and ready to sync

### Important Finding
From `source/FORK_CHANGELOG.md` - We DID add `-job-id` and `-user-id` flags to the scraper, but they only work in DSN mode (which requires `gmaps_jobs` table). Not usable without that table.

## What's Left to Do

1. **Test the JSON workflow end-to-end:**
   - Clean up old containers: `docker rm lcc-job-a7ca3b43 lcc-job-8ccfc5df lcc-job-8d0f453a`
   - Start a new job via the web UI
   - Wait for container to exit
   - Call `POST /api/jobs/[jobId]/sync` to process results
   - Verify leads appear in Supabase and UI

2. **Implement automatic sync:**
   - Option A: Polling - UI periodically checks container status, triggers sync when exited
   - Option B: Background job - Node.js watches containers and auto-syncs on exit
   - Option C: Manual sync button in UI

3. **UI integration:**
   - Add a "Sync Results" button for completed jobs
   - Or implement automatic polling/sync

4. **Restore `--rm` flag** in docker.ts (currently commented for debugging)

## Known Issues

- File permission issue creating files in `cli_test` directory (Docker volume mount issue)
- Container logs show successful scrape but UI shows 0 leads (because sync not called yet)

## How to Verify Current State
```powershell
cd D:\Websites\GMaps_scraper_gosom\leads-command-center
npm run dev
# Navigate to http://localhost:3000
# Create a new job with "pizza milan" query
# Wait ~2-3 minutes for container to exit
# Check: docker ps -a --filter "name=lcc-job"
# When exited, call: curl -X POST http://localhost:3000/api/jobs/[JOB_ID]/sync
```

## Suggested First Action
Test the complete flow manually:
1. Create new job via UI
2. Monitor with `docker logs -f lcc-job-[first8chars]`
3. When container exits, call sync API
4. Check Supabase `results` table for inserted leads
